// clang-format off
// DO NOT EDIT;
// Generated by ml/nn/runtime/test/specs/generate_vts_test.sh
// Generated from: add.mod.py.
namespace add {
// Generated add test
#include "examples/add.example.cpp"
// Generated model constructor
#include "vts_models/add.model.cpp"
} // namespace add

TEST_F(NeuralnetworksHidlTest, add) {
  generated_tests::Execute(device,
                           add::createTestModel,
                           add::is_ignored,
                           add::examples);
}

// Generated from: add_broadcast_quant8.mod.py.
namespace add_broadcast_quant8 {
// Generated add_broadcast_quant8 test
#include "examples/add_broadcast_quant8.example.cpp"
// Generated model constructor
#include "vts_models/add_broadcast_quant8.model.cpp"
} // namespace add_broadcast_quant8

TEST_F(NeuralnetworksHidlTest, add_broadcast_quant8) {
  generated_tests::Execute(device,
                           add_broadcast_quant8::createTestModel,
                           add_broadcast_quant8::is_ignored,
                           add_broadcast_quant8::examples);
}

// Generated from: add_quant8.mod.py.
namespace add_quant8 {
// Generated add_quant8 test
#include "examples/add_quant8.example.cpp"
// Generated model constructor
#include "vts_models/add_quant8.model.cpp"
} // namespace add_quant8

TEST_F(NeuralnetworksHidlTest, add_quant8) {
  generated_tests::Execute(device,
                           add_quant8::createTestModel,
                           add_quant8::is_ignored,
                           add_quant8::examples);
}

// Generated from: avg_pool_float_1.mod.py.
namespace avg_pool_float_1 {
// Generated avg_pool_float_1 test
#include "examples/avg_pool_float_1.example.cpp"
// Generated model constructor
#include "vts_models/avg_pool_float_1.model.cpp"
} // namespace avg_pool_float_1

TEST_F(NeuralnetworksHidlTest, avg_pool_float_1) {
  generated_tests::Execute(device,
                           avg_pool_float_1::createTestModel,
                           avg_pool_float_1::is_ignored,
                           avg_pool_float_1::examples);
}

// Generated from: avg_pool_float_2.mod.py.
namespace avg_pool_float_2 {
// Generated avg_pool_float_2 test
#include "examples/avg_pool_float_2.example.cpp"
// Generated model constructor
#include "vts_models/avg_pool_float_2.model.cpp"
} // namespace avg_pool_float_2

TEST_F(NeuralnetworksHidlTest, avg_pool_float_2) {
  generated_tests::Execute(device,
                           avg_pool_float_2::createTestModel,
                           avg_pool_float_2::is_ignored,
                           avg_pool_float_2::examples);
}

// Generated from: avg_pool_float_3.mod.py.
namespace avg_pool_float_3 {
// Generated avg_pool_float_3 test
#include "examples/avg_pool_float_3.example.cpp"
// Generated model constructor
#include "vts_models/avg_pool_float_3.model.cpp"
} // namespace avg_pool_float_3

TEST_F(NeuralnetworksHidlTest, avg_pool_float_3) {
  generated_tests::Execute(device,
                           avg_pool_float_3::createTestModel,
                           avg_pool_float_3::is_ignored,
                           avg_pool_float_3::examples);
}

// Generated from: avg_pool_float_4.mod.py.
namespace avg_pool_float_4 {
// Generated avg_pool_float_4 test
#include "examples/avg_pool_float_4.example.cpp"
// Generated model constructor
#include "vts_models/avg_pool_float_4.model.cpp"
} // namespace avg_pool_float_4

TEST_F(NeuralnetworksHidlTest, avg_pool_float_4) {
  generated_tests::Execute(device,
                           avg_pool_float_4::createTestModel,
                           avg_pool_float_4::is_ignored,
                           avg_pool_float_4::examples);
}

// Generated from: avg_pool_float_5.mod.py.
namespace avg_pool_float_5 {
// Generated avg_pool_float_5 test
#include "examples/avg_pool_float_5.example.cpp"
// Generated model constructor
#include "vts_models/avg_pool_float_5.model.cpp"
} // namespace avg_pool_float_5

TEST_F(NeuralnetworksHidlTest, avg_pool_float_5) {
  generated_tests::Execute(device,
                           avg_pool_float_5::createTestModel,
                           avg_pool_float_5::is_ignored,
                           avg_pool_float_5::examples);
}

// Generated from: avg_pool_quant8_1.mod.py.
namespace avg_pool_quant8_1 {
// Generated avg_pool_quant8_1 test
#include "examples/avg_pool_quant8_1.example.cpp"
// Generated model constructor
#include "vts_models/avg_pool_quant8_1.model.cpp"
} // namespace avg_pool_quant8_1

TEST_F(NeuralnetworksHidlTest, avg_pool_quant8_1) {
  generated_tests::Execute(device,
                           avg_pool_quant8_1::createTestModel,
                           avg_pool_quant8_1::is_ignored,
                           avg_pool_quant8_1::examples);
}

// Generated from: avg_pool_quant8_2.mod.py.
namespace avg_pool_quant8_2 {
// Generated avg_pool_quant8_2 test
#include "examples/avg_pool_quant8_2.example.cpp"
// Generated model constructor
#include "vts_models/avg_pool_quant8_2.model.cpp"
} // namespace avg_pool_quant8_2

TEST_F(NeuralnetworksHidlTest, avg_pool_quant8_2) {
  generated_tests::Execute(device,
                           avg_pool_quant8_2::createTestModel,
                           avg_pool_quant8_2::is_ignored,
                           avg_pool_quant8_2::examples);
}

// Generated from: avg_pool_quant8_3.mod.py.
namespace avg_pool_quant8_3 {
// Generated avg_pool_quant8_3 test
#include "examples/avg_pool_quant8_3.example.cpp"
// Generated model constructor
#include "vts_models/avg_pool_quant8_3.model.cpp"
} // namespace avg_pool_quant8_3

TEST_F(NeuralnetworksHidlTest, avg_pool_quant8_3) {
  generated_tests::Execute(device,
                           avg_pool_quant8_3::createTestModel,
                           avg_pool_quant8_3::is_ignored,
                           avg_pool_quant8_3::examples);
}

// Generated from: avg_pool_quant8_4.mod.py.
namespace avg_pool_quant8_4 {
// Generated avg_pool_quant8_4 test
#include "examples/avg_pool_quant8_4.example.cpp"
// Generated model constructor
#include "vts_models/avg_pool_quant8_4.model.cpp"
} // namespace avg_pool_quant8_4

TEST_F(NeuralnetworksHidlTest, avg_pool_quant8_4) {
  generated_tests::Execute(device,
                           avg_pool_quant8_4::createTestModel,
                           avg_pool_quant8_4::is_ignored,
                           avg_pool_quant8_4::examples);
}

// Generated from: avg_pool_quant8_5.mod.py.
namespace avg_pool_quant8_5 {
// Generated avg_pool_quant8_5 test
#include "examples/avg_pool_quant8_5.example.cpp"
// Generated model constructor
#include "vts_models/avg_pool_quant8_5.model.cpp"
} // namespace avg_pool_quant8_5

TEST_F(NeuralnetworksHidlTest, avg_pool_quant8_5) {
  generated_tests::Execute(device,
                           avg_pool_quant8_5::createTestModel,
                           avg_pool_quant8_5::is_ignored,
                           avg_pool_quant8_5::examples);
}

// Generated from: concat_float_1.mod.py.
namespace concat_float_1 {
// Generated concat_float_1 test
#include "examples/concat_float_1.example.cpp"
// Generated model constructor
#include "vts_models/concat_float_1.model.cpp"
} // namespace concat_float_1

TEST_F(NeuralnetworksHidlTest, concat_float_1) {
  generated_tests::Execute(device,
                           concat_float_1::createTestModel,
                           concat_float_1::is_ignored,
                           concat_float_1::examples);
}

// Generated from: concat_float_2.mod.py.
namespace concat_float_2 {
// Generated concat_float_2 test
#include "examples/concat_float_2.example.cpp"
// Generated model constructor
#include "vts_models/concat_float_2.model.cpp"
} // namespace concat_float_2

TEST_F(NeuralnetworksHidlTest, concat_float_2) {
  generated_tests::Execute(device,
                           concat_float_2::createTestModel,
                           concat_float_2::is_ignored,
                           concat_float_2::examples);
}

// Generated from: concat_float_3.mod.py.
namespace concat_float_3 {
// Generated concat_float_3 test
#include "examples/concat_float_3.example.cpp"
// Generated model constructor
#include "vts_models/concat_float_3.model.cpp"
} // namespace concat_float_3

TEST_F(NeuralnetworksHidlTest, concat_float_3) {
  generated_tests::Execute(device,
                           concat_float_3::createTestModel,
                           concat_float_3::is_ignored,
                           concat_float_3::examples);
}

// Generated from: concat_quant8_1.mod.py.
namespace concat_quant8_1 {
// Generated concat_quant8_1 test
#include "examples/concat_quant8_1.example.cpp"
// Generated model constructor
#include "vts_models/concat_quant8_1.model.cpp"
} // namespace concat_quant8_1

TEST_F(NeuralnetworksHidlTest, concat_quant8_1) {
  generated_tests::Execute(device,
                           concat_quant8_1::createTestModel,
                           concat_quant8_1::is_ignored,
                           concat_quant8_1::examples);
}

// Generated from: concat_quant8_2.mod.py.
namespace concat_quant8_2 {
// Generated concat_quant8_2 test
#include "examples/concat_quant8_2.example.cpp"
// Generated model constructor
#include "vts_models/concat_quant8_2.model.cpp"
} // namespace concat_quant8_2

TEST_F(NeuralnetworksHidlTest, concat_quant8_2) {
  generated_tests::Execute(device,
                           concat_quant8_2::createTestModel,
                           concat_quant8_2::is_ignored,
                           concat_quant8_2::examples);
}

// Generated from: concat_quant8_3.mod.py.
namespace concat_quant8_3 {
// Generated concat_quant8_3 test
#include "examples/concat_quant8_3.example.cpp"
// Generated model constructor
#include "vts_models/concat_quant8_3.model.cpp"
} // namespace concat_quant8_3

TEST_F(NeuralnetworksHidlTest, concat_quant8_3) {
  generated_tests::Execute(device,
                           concat_quant8_3::createTestModel,
                           concat_quant8_3::is_ignored,
                           concat_quant8_3::examples);
}

// Generated from: conv_1_h3_w2_SAME.mod.py.
namespace conv_1_h3_w2_SAME {
// Generated conv_1_h3_w2_SAME test
#include "examples/conv_1_h3_w2_SAME.example.cpp"
// Generated model constructor
#include "vts_models/conv_1_h3_w2_SAME.model.cpp"
} // namespace conv_1_h3_w2_SAME

TEST_F(NeuralnetworksHidlTest, conv_1_h3_w2_SAME) {
  generated_tests::Execute(device,
                           conv_1_h3_w2_SAME::createTestModel,
                           conv_1_h3_w2_SAME::is_ignored,
                           conv_1_h3_w2_SAME::examples);
}

// Generated from: conv_1_h3_w2_VALID.mod.py.
namespace conv_1_h3_w2_VALID {
// Generated conv_1_h3_w2_VALID test
#include "examples/conv_1_h3_w2_VALID.example.cpp"
// Generated model constructor
#include "vts_models/conv_1_h3_w2_VALID.model.cpp"
} // namespace conv_1_h3_w2_VALID

TEST_F(NeuralnetworksHidlTest, conv_1_h3_w2_VALID) {
  generated_tests::Execute(device,
                           conv_1_h3_w2_VALID::createTestModel,
                           conv_1_h3_w2_VALID::is_ignored,
                           conv_1_h3_w2_VALID::examples);
}

// Generated from: conv_3_h3_w2_SAME.mod.py.
namespace conv_3_h3_w2_SAME {
// Generated conv_3_h3_w2_SAME test
#include "examples/conv_3_h3_w2_SAME.example.cpp"
// Generated model constructor
#include "vts_models/conv_3_h3_w2_SAME.model.cpp"
} // namespace conv_3_h3_w2_SAME

TEST_F(NeuralnetworksHidlTest, conv_3_h3_w2_SAME) {
  generated_tests::Execute(device,
                           conv_3_h3_w2_SAME::createTestModel,
                           conv_3_h3_w2_SAME::is_ignored,
                           conv_3_h3_w2_SAME::examples);
}

// Generated from: conv_3_h3_w2_VALID.mod.py.
namespace conv_3_h3_w2_VALID {
// Generated conv_3_h3_w2_VALID test
#include "examples/conv_3_h3_w2_VALID.example.cpp"
// Generated model constructor
#include "vts_models/conv_3_h3_w2_VALID.model.cpp"
} // namespace conv_3_h3_w2_VALID

TEST_F(NeuralnetworksHidlTest, conv_3_h3_w2_VALID) {
  generated_tests::Execute(device,
                           conv_3_h3_w2_VALID::createTestModel,
                           conv_3_h3_w2_VALID::is_ignored,
                           conv_3_h3_w2_VALID::examples);
}

// Generated from: conv_float.mod.py.
namespace conv_float {
// Generated conv_float test
#include "examples/conv_float.example.cpp"
// Generated model constructor
#include "vts_models/conv_float.model.cpp"
} // namespace conv_float

TEST_F(NeuralnetworksHidlTest, conv_float) {
  generated_tests::Execute(device,
                           conv_float::createTestModel,
                           conv_float::is_ignored,
                           conv_float::examples);
}

// Generated from: conv_float_2.mod.py.
namespace conv_float_2 {
// Generated conv_float_2 test
#include "examples/conv_float_2.example.cpp"
// Generated model constructor
#include "vts_models/conv_float_2.model.cpp"
} // namespace conv_float_2

TEST_F(NeuralnetworksHidlTest, conv_float_2) {
  generated_tests::Execute(device,
                           conv_float_2::createTestModel,
                           conv_float_2::is_ignored,
                           conv_float_2::examples);
}

// Generated from: conv_float_channels.mod.py.
namespace conv_float_channels {
// Generated conv_float_channels test
#include "examples/conv_float_channels.example.cpp"
// Generated model constructor
#include "vts_models/conv_float_channels.model.cpp"
} // namespace conv_float_channels

TEST_F(NeuralnetworksHidlTest, conv_float_channels) {
  generated_tests::Execute(device,
                           conv_float_channels::createTestModel,
                           conv_float_channels::is_ignored,
                           conv_float_channels::examples);
}

// Generated from: conv_float_channels_weights_as_inputs.mod.py.
namespace conv_float_channels_weights_as_inputs {
// Generated conv_float_channels_weights_as_inputs test
#include "examples/conv_float_channels_weights_as_inputs.example.cpp"
// Generated model constructor
#include "vts_models/conv_float_channels_weights_as_inputs.model.cpp"
} // namespace conv_float_channels_weights_as_inputs

TEST_F(NeuralnetworksHidlTest, conv_float_channels_weights_as_inputs) {
  generated_tests::Execute(device,
                           conv_float_channels_weights_as_inputs::createTestModel,
                           conv_float_channels_weights_as_inputs::is_ignored,
                           conv_float_channels_weights_as_inputs::examples);
}

// Generated from: conv_float_large.mod.py.
namespace conv_float_large {
// Generated conv_float_large test
#include "examples/conv_float_large.example.cpp"
// Generated model constructor
#include "vts_models/conv_float_large.model.cpp"
} // namespace conv_float_large

TEST_F(NeuralnetworksHidlTest, conv_float_large) {
  generated_tests::Execute(device,
                           conv_float_large::createTestModel,
                           conv_float_large::is_ignored,
                           conv_float_large::examples);
}

// Generated from: conv_float_large_weights_as_inputs.mod.py.
namespace conv_float_large_weights_as_inputs {
// Generated conv_float_large_weights_as_inputs test
#include "examples/conv_float_large_weights_as_inputs.example.cpp"
// Generated model constructor
#include "vts_models/conv_float_large_weights_as_inputs.model.cpp"
} // namespace conv_float_large_weights_as_inputs

TEST_F(NeuralnetworksHidlTest, conv_float_large_weights_as_inputs) {
  generated_tests::Execute(device,
                           conv_float_large_weights_as_inputs::createTestModel,
                           conv_float_large_weights_as_inputs::is_ignored,
                           conv_float_large_weights_as_inputs::examples);
}

// Generated from: conv_float_weights_as_inputs.mod.py.
namespace conv_float_weights_as_inputs {
// Generated conv_float_weights_as_inputs test
#include "examples/conv_float_weights_as_inputs.example.cpp"
// Generated model constructor
#include "vts_models/conv_float_weights_as_inputs.model.cpp"
} // namespace conv_float_weights_as_inputs

TEST_F(NeuralnetworksHidlTest, conv_float_weights_as_inputs) {
  generated_tests::Execute(device,
                           conv_float_weights_as_inputs::createTestModel,
                           conv_float_weights_as_inputs::is_ignored,
                           conv_float_weights_as_inputs::examples);
}

// Generated from: conv_quant8.mod.py.
namespace conv_quant8 {
// Generated conv_quant8 test
#include "examples/conv_quant8.example.cpp"
// Generated model constructor
#include "vts_models/conv_quant8.model.cpp"
} // namespace conv_quant8

TEST_F(NeuralnetworksHidlTest, conv_quant8) {
  generated_tests::Execute(device,
                           conv_quant8::createTestModel,
                           conv_quant8::is_ignored,
                           conv_quant8::examples);
}

// Generated from: conv_quant8_2.mod.py.
namespace conv_quant8_2 {
// Generated conv_quant8_2 test
#include "examples/conv_quant8_2.example.cpp"
// Generated model constructor
#include "vts_models/conv_quant8_2.model.cpp"
} // namespace conv_quant8_2

TEST_F(NeuralnetworksHidlTest, conv_quant8_2) {
  generated_tests::Execute(device,
                           conv_quant8_2::createTestModel,
                           conv_quant8_2::is_ignored,
                           conv_quant8_2::examples);
}

// Generated from: conv_quant8_channels.mod.py.
namespace conv_quant8_channels {
// Generated conv_quant8_channels test
#include "examples/conv_quant8_channels.example.cpp"
// Generated model constructor
#include "vts_models/conv_quant8_channels.model.cpp"
} // namespace conv_quant8_channels

TEST_F(NeuralnetworksHidlTest, conv_quant8_channels) {
  generated_tests::Execute(device,
                           conv_quant8_channels::createTestModel,
                           conv_quant8_channels::is_ignored,
                           conv_quant8_channels::examples);
}

// Generated from: conv_quant8_channels_weights_as_inputs.mod.py.
namespace conv_quant8_channels_weights_as_inputs {
// Generated conv_quant8_channels_weights_as_inputs test
#include "examples/conv_quant8_channels_weights_as_inputs.example.cpp"
// Generated model constructor
#include "vts_models/conv_quant8_channels_weights_as_inputs.model.cpp"
} // namespace conv_quant8_channels_weights_as_inputs

TEST_F(NeuralnetworksHidlTest, conv_quant8_channels_weights_as_inputs) {
  generated_tests::Execute(device,
                           conv_quant8_channels_weights_as_inputs::createTestModel,
                           conv_quant8_channels_weights_as_inputs::is_ignored,
                           conv_quant8_channels_weights_as_inputs::examples);
}

// Generated from: conv_quant8_large.mod.py.
namespace conv_quant8_large {
// Generated conv_quant8_large test
#include "examples/conv_quant8_large.example.cpp"
// Generated model constructor
#include "vts_models/conv_quant8_large.model.cpp"
} // namespace conv_quant8_large

TEST_F(NeuralnetworksHidlTest, conv_quant8_large) {
  generated_tests::Execute(device,
                           conv_quant8_large::createTestModel,
                           conv_quant8_large::is_ignored,
                           conv_quant8_large::examples);
}

// Generated from: conv_quant8_large_weights_as_inputs.mod.py.
namespace conv_quant8_large_weights_as_inputs {
// Generated conv_quant8_large_weights_as_inputs test
#include "examples/conv_quant8_large_weights_as_inputs.example.cpp"
// Generated model constructor
#include "vts_models/conv_quant8_large_weights_as_inputs.model.cpp"
} // namespace conv_quant8_large_weights_as_inputs

TEST_F(NeuralnetworksHidlTest, conv_quant8_large_weights_as_inputs) {
  generated_tests::Execute(device,
                           conv_quant8_large_weights_as_inputs::createTestModel,
                           conv_quant8_large_weights_as_inputs::is_ignored,
                           conv_quant8_large_weights_as_inputs::examples);
}

// Generated from: conv_quant8_overflow.mod.py.
namespace conv_quant8_overflow {
// Generated conv_quant8_overflow test
#include "examples/conv_quant8_overflow.example.cpp"
// Generated model constructor
#include "vts_models/conv_quant8_overflow.model.cpp"
} // namespace conv_quant8_overflow

TEST_F(NeuralnetworksHidlTest, conv_quant8_overflow) {
  generated_tests::Execute(device,
                           conv_quant8_overflow::createTestModel,
                           conv_quant8_overflow::is_ignored,
                           conv_quant8_overflow::examples);
}

// Generated from: conv_quant8_overflow_weights_as_inputs.mod.py.
namespace conv_quant8_overflow_weights_as_inputs {
// Generated conv_quant8_overflow_weights_as_inputs test
#include "examples/conv_quant8_overflow_weights_as_inputs.example.cpp"
// Generated model constructor
#include "vts_models/conv_quant8_overflow_weights_as_inputs.model.cpp"
} // namespace conv_quant8_overflow_weights_as_inputs

TEST_F(NeuralnetworksHidlTest, conv_quant8_overflow_weights_as_inputs) {
  generated_tests::Execute(device,
                           conv_quant8_overflow_weights_as_inputs::createTestModel,
                           conv_quant8_overflow_weights_as_inputs::is_ignored,
                           conv_quant8_overflow_weights_as_inputs::examples);
}

// Generated from: conv_quant8_weights_as_inputs.mod.py.
namespace conv_quant8_weights_as_inputs {
// Generated conv_quant8_weights_as_inputs test
#include "examples/conv_quant8_weights_as_inputs.example.cpp"
// Generated model constructor
#include "vts_models/conv_quant8_weights_as_inputs.model.cpp"
} // namespace conv_quant8_weights_as_inputs

TEST_F(NeuralnetworksHidlTest, conv_quant8_weights_as_inputs) {
  generated_tests::Execute(device,
                           conv_quant8_weights_as_inputs::createTestModel,
                           conv_quant8_weights_as_inputs::is_ignored,
                           conv_quant8_weights_as_inputs::examples);
}

// Generated from: depth_to_space_float_1.mod.py.
namespace depth_to_space_float_1 {
// Generated depth_to_space_float_1 test
#include "examples/depth_to_space_float_1.example.cpp"
// Generated model constructor
#include "vts_models/depth_to_space_float_1.model.cpp"
} // namespace depth_to_space_float_1

TEST_F(NeuralnetworksHidlTest, depth_to_space_float_1) {
  generated_tests::Execute(device,
                           depth_to_space_float_1::createTestModel,
                           depth_to_space_float_1::is_ignored,
                           depth_to_space_float_1::examples);
}

// Generated from: depth_to_space_float_2.mod.py.
namespace depth_to_space_float_2 {
// Generated depth_to_space_float_2 test
#include "examples/depth_to_space_float_2.example.cpp"
// Generated model constructor
#include "vts_models/depth_to_space_float_2.model.cpp"
} // namespace depth_to_space_float_2

TEST_F(NeuralnetworksHidlTest, depth_to_space_float_2) {
  generated_tests::Execute(device,
                           depth_to_space_float_2::createTestModel,
                           depth_to_space_float_2::is_ignored,
                           depth_to_space_float_2::examples);
}

// Generated from: depth_to_space_float_3.mod.py.
namespace depth_to_space_float_3 {
// Generated depth_to_space_float_3 test
#include "examples/depth_to_space_float_3.example.cpp"
// Generated model constructor
#include "vts_models/depth_to_space_float_3.model.cpp"
} // namespace depth_to_space_float_3

TEST_F(NeuralnetworksHidlTest, depth_to_space_float_3) {
  generated_tests::Execute(device,
                           depth_to_space_float_3::createTestModel,
                           depth_to_space_float_3::is_ignored,
                           depth_to_space_float_3::examples);
}

// Generated from: depth_to_space_quant8_1.mod.py.
namespace depth_to_space_quant8_1 {
// Generated depth_to_space_quant8_1 test
#include "examples/depth_to_space_quant8_1.example.cpp"
// Generated model constructor
#include "vts_models/depth_to_space_quant8_1.model.cpp"
} // namespace depth_to_space_quant8_1

TEST_F(NeuralnetworksHidlTest, depth_to_space_quant8_1) {
  generated_tests::Execute(device,
                           depth_to_space_quant8_1::createTestModel,
                           depth_to_space_quant8_1::is_ignored,
                           depth_to_space_quant8_1::examples);
}

// Generated from: depth_to_space_quant8_2.mod.py.
namespace depth_to_space_quant8_2 {
// Generated depth_to_space_quant8_2 test
#include "examples/depth_to_space_quant8_2.example.cpp"
// Generated model constructor
#include "vts_models/depth_to_space_quant8_2.model.cpp"
} // namespace depth_to_space_quant8_2

TEST_F(NeuralnetworksHidlTest, depth_to_space_quant8_2) {
  generated_tests::Execute(device,
                           depth_to_space_quant8_2::createTestModel,
                           depth_to_space_quant8_2::is_ignored,
                           depth_to_space_quant8_2::examples);
}

// Generated from: depthwise_conv.mod.py.
namespace depthwise_conv {
// Generated depthwise_conv test
#include "examples/depthwise_conv.example.cpp"
// Generated model constructor
#include "vts_models/depthwise_conv.model.cpp"
} // namespace depthwise_conv

TEST_F(NeuralnetworksHidlTest, depthwise_conv) {
  generated_tests::Execute(device,
                           depthwise_conv::createTestModel,
                           depthwise_conv::is_ignored,
                           depthwise_conv::examples);
}

// Generated from: depthwise_conv2d_float.mod.py.
namespace depthwise_conv2d_float {
// Generated depthwise_conv2d_float test
#include "examples/depthwise_conv2d_float.example.cpp"
// Generated model constructor
#include "vts_models/depthwise_conv2d_float.model.cpp"
} // namespace depthwise_conv2d_float

TEST_F(NeuralnetworksHidlTest, depthwise_conv2d_float) {
  generated_tests::Execute(device,
                           depthwise_conv2d_float::createTestModel,
                           depthwise_conv2d_float::is_ignored,
                           depthwise_conv2d_float::examples);
}

// Generated from: depthwise_conv2d_float_2.mod.py.
namespace depthwise_conv2d_float_2 {
// Generated depthwise_conv2d_float_2 test
#include "examples/depthwise_conv2d_float_2.example.cpp"
// Generated model constructor
#include "vts_models/depthwise_conv2d_float_2.model.cpp"
} // namespace depthwise_conv2d_float_2

TEST_F(NeuralnetworksHidlTest, depthwise_conv2d_float_2) {
  generated_tests::Execute(device,
                           depthwise_conv2d_float_2::createTestModel,
                           depthwise_conv2d_float_2::is_ignored,
                           depthwise_conv2d_float_2::examples);
}

// Generated from: depthwise_conv2d_float_large.mod.py.
namespace depthwise_conv2d_float_large {
// Generated depthwise_conv2d_float_large test
#include "examples/depthwise_conv2d_float_large.example.cpp"
// Generated model constructor
#include "vts_models/depthwise_conv2d_float_large.model.cpp"
} // namespace depthwise_conv2d_float_large

TEST_F(NeuralnetworksHidlTest, depthwise_conv2d_float_large) {
  generated_tests::Execute(device,
                           depthwise_conv2d_float_large::createTestModel,
                           depthwise_conv2d_float_large::is_ignored,
                           depthwise_conv2d_float_large::examples);
}

// Generated from: depthwise_conv2d_float_large_2.mod.py.
namespace depthwise_conv2d_float_large_2 {
// Generated depthwise_conv2d_float_large_2 test
#include "examples/depthwise_conv2d_float_large_2.example.cpp"
// Generated model constructor
#include "vts_models/depthwise_conv2d_float_large_2.model.cpp"
} // namespace depthwise_conv2d_float_large_2

TEST_F(NeuralnetworksHidlTest, depthwise_conv2d_float_large_2) {
  generated_tests::Execute(device,
                           depthwise_conv2d_float_large_2::createTestModel,
                           depthwise_conv2d_float_large_2::is_ignored,
                           depthwise_conv2d_float_large_2::examples);
}

// Generated from: depthwise_conv2d_float_large_2_weights_as_inputs.mod.py.
namespace depthwise_conv2d_float_large_2_weights_as_inputs {
// Generated depthwise_conv2d_float_large_2_weights_as_inputs test
#include "examples/depthwise_conv2d_float_large_2_weights_as_inputs.example.cpp"
// Generated model constructor
#include "vts_models/depthwise_conv2d_float_large_2_weights_as_inputs.model.cpp"
} // namespace depthwise_conv2d_float_large_2_weights_as_inputs

TEST_F(NeuralnetworksHidlTest, depthwise_conv2d_float_large_2_weights_as_inputs) {
  generated_tests::Execute(device,
                           depthwise_conv2d_float_large_2_weights_as_inputs::createTestModel,
                           depthwise_conv2d_float_large_2_weights_as_inputs::is_ignored,
                           depthwise_conv2d_float_large_2_weights_as_inputs::examples);
}

// Generated from: depthwise_conv2d_float_large_weights_as_inputs.mod.py.
namespace depthwise_conv2d_float_large_weights_as_inputs {
// Generated depthwise_conv2d_float_large_weights_as_inputs test
#include "examples/depthwise_conv2d_float_large_weights_as_inputs.example.cpp"
// Generated model constructor
#include "vts_models/depthwise_conv2d_float_large_weights_as_inputs.model.cpp"
} // namespace depthwise_conv2d_float_large_weights_as_inputs

TEST_F(NeuralnetworksHidlTest, depthwise_conv2d_float_large_weights_as_inputs) {
  generated_tests::Execute(device,
                           depthwise_conv2d_float_large_weights_as_inputs::createTestModel,
                           depthwise_conv2d_float_large_weights_as_inputs::is_ignored,
                           depthwise_conv2d_float_large_weights_as_inputs::examples);
}

// Generated from: depthwise_conv2d_float_weights_as_inputs.mod.py.
namespace depthwise_conv2d_float_weights_as_inputs {
// Generated depthwise_conv2d_float_weights_as_inputs test
#include "examples/depthwise_conv2d_float_weights_as_inputs.example.cpp"
// Generated model constructor
#include "vts_models/depthwise_conv2d_float_weights_as_inputs.model.cpp"
} // namespace depthwise_conv2d_float_weights_as_inputs

TEST_F(NeuralnetworksHidlTest, depthwise_conv2d_float_weights_as_inputs) {
  generated_tests::Execute(device,
                           depthwise_conv2d_float_weights_as_inputs::createTestModel,
                           depthwise_conv2d_float_weights_as_inputs::is_ignored,
                           depthwise_conv2d_float_weights_as_inputs::examples);
}

// Generated from: depthwise_conv2d_quant8.mod.py.
namespace depthwise_conv2d_quant8 {
// Generated depthwise_conv2d_quant8 test
#include "examples/depthwise_conv2d_quant8.example.cpp"
// Generated model constructor
#include "vts_models/depthwise_conv2d_quant8.model.cpp"
} // namespace depthwise_conv2d_quant8

TEST_F(NeuralnetworksHidlTest, depthwise_conv2d_quant8) {
  generated_tests::Execute(device,
                           depthwise_conv2d_quant8::createTestModel,
                           depthwise_conv2d_quant8::is_ignored,
                           depthwise_conv2d_quant8::examples);
}

// Generated from: depthwise_conv2d_quant8_2.mod.py.
namespace depthwise_conv2d_quant8_2 {
// Generated depthwise_conv2d_quant8_2 test
#include "examples/depthwise_conv2d_quant8_2.example.cpp"
// Generated model constructor
#include "vts_models/depthwise_conv2d_quant8_2.model.cpp"
} // namespace depthwise_conv2d_quant8_2

TEST_F(NeuralnetworksHidlTest, depthwise_conv2d_quant8_2) {
  generated_tests::Execute(device,
                           depthwise_conv2d_quant8_2::createTestModel,
                           depthwise_conv2d_quant8_2::is_ignored,
                           depthwise_conv2d_quant8_2::examples);
}

// Generated from: depthwise_conv2d_quant8_large.mod.py.
namespace depthwise_conv2d_quant8_large {
// Generated depthwise_conv2d_quant8_large test
#include "examples/depthwise_conv2d_quant8_large.example.cpp"
// Generated model constructor
#include "vts_models/depthwise_conv2d_quant8_large.model.cpp"
} // namespace depthwise_conv2d_quant8_large

TEST_F(NeuralnetworksHidlTest, depthwise_conv2d_quant8_large) {
  generated_tests::Execute(device,
                           depthwise_conv2d_quant8_large::createTestModel,
                           depthwise_conv2d_quant8_large::is_ignored,
                           depthwise_conv2d_quant8_large::examples);
}

// Generated from: depthwise_conv2d_quant8_large_weights_as_inputs.mod.py.
namespace depthwise_conv2d_quant8_large_weights_as_inputs {
// Generated depthwise_conv2d_quant8_large_weights_as_inputs test
#include "examples/depthwise_conv2d_quant8_large_weights_as_inputs.example.cpp"
// Generated model constructor
#include "vts_models/depthwise_conv2d_quant8_large_weights_as_inputs.model.cpp"
} // namespace depthwise_conv2d_quant8_large_weights_as_inputs

TEST_F(NeuralnetworksHidlTest, depthwise_conv2d_quant8_large_weights_as_inputs) {
  generated_tests::Execute(device,
                           depthwise_conv2d_quant8_large_weights_as_inputs::createTestModel,
                           depthwise_conv2d_quant8_large_weights_as_inputs::is_ignored,
                           depthwise_conv2d_quant8_large_weights_as_inputs::examples);
}

// Generated from: depthwise_conv2d_quant8_weights_as_inputs.mod.py.
namespace depthwise_conv2d_quant8_weights_as_inputs {
// Generated depthwise_conv2d_quant8_weights_as_inputs test
#include "examples/depthwise_conv2d_quant8_weights_as_inputs.example.cpp"
// Generated model constructor
#include "vts_models/depthwise_conv2d_quant8_weights_as_inputs.model.cpp"
} // namespace depthwise_conv2d_quant8_weights_as_inputs

TEST_F(NeuralnetworksHidlTest, depthwise_conv2d_quant8_weights_as_inputs) {
  generated_tests::Execute(device,
                           depthwise_conv2d_quant8_weights_as_inputs::createTestModel,
                           depthwise_conv2d_quant8_weights_as_inputs::is_ignored,
                           depthwise_conv2d_quant8_weights_as_inputs::examples);
}

// Generated from: dequantize.mod.py.
namespace dequantize {
// Generated dequantize test
#include "examples/dequantize.example.cpp"
// Generated model constructor
#include "vts_models/dequantize.model.cpp"
} // namespace dequantize

TEST_F(NeuralnetworksHidlTest, dequantize) {
  generated_tests::Execute(device,
                           dequantize::createTestModel,
                           dequantize::is_ignored,
                           dequantize::examples);
}

// Generated from: embedding_lookup.mod.py.
namespace embedding_lookup {
// Generated embedding_lookup test
#include "examples/embedding_lookup.example.cpp"
// Generated model constructor
#include "vts_models/embedding_lookup.model.cpp"
} // namespace embedding_lookup

TEST_F(NeuralnetworksHidlTest, embedding_lookup) {
  generated_tests::Execute(device,
                           embedding_lookup::createTestModel,
                           embedding_lookup::is_ignored,
                           embedding_lookup::examples);
}

// Generated from: floor.mod.py.
namespace floor {
// Generated floor test
#include "examples/floor.example.cpp"
// Generated model constructor
#include "vts_models/floor.model.cpp"
} // namespace floor

TEST_F(NeuralnetworksHidlTest, floor) {
  generated_tests::Execute(device,
                           floor::createTestModel,
                           floor::is_ignored,
                           floor::examples);
}

// Generated from: fully_connected_float.mod.py.
namespace fully_connected_float {
// Generated fully_connected_float test
#include "examples/fully_connected_float.example.cpp"
// Generated model constructor
#include "vts_models/fully_connected_float.model.cpp"
} // namespace fully_connected_float

TEST_F(NeuralnetworksHidlTest, fully_connected_float) {
  generated_tests::Execute(device,
                           fully_connected_float::createTestModel,
                           fully_connected_float::is_ignored,
                           fully_connected_float::examples);
}

// Generated from: fully_connected_float_2.mod.py.
namespace fully_connected_float_2 {
// Generated fully_connected_float_2 test
#include "examples/fully_connected_float_2.example.cpp"
// Generated model constructor
#include "vts_models/fully_connected_float_2.model.cpp"
} // namespace fully_connected_float_2

TEST_F(NeuralnetworksHidlTest, fully_connected_float_2) {
  generated_tests::Execute(device,
                           fully_connected_float_2::createTestModel,
                           fully_connected_float_2::is_ignored,
                           fully_connected_float_2::examples);
}

// Generated from: fully_connected_float_3.mod.py.
namespace fully_connected_float_3 {
// Generated fully_connected_float_3 test
#include "examples/fully_connected_float_3.example.cpp"
// Generated model constructor
#include "vts_models/fully_connected_float_3.model.cpp"
} // namespace fully_connected_float_3

TEST_F(NeuralnetworksHidlTest, fully_connected_float_3) {
  generated_tests::Execute(device,
                           fully_connected_float_3::createTestModel,
                           fully_connected_float_3::is_ignored,
                           fully_connected_float_3::examples);
}

// Generated from: fully_connected_float_large.mod.py.
namespace fully_connected_float_large {
// Generated fully_connected_float_large test
#include "examples/fully_connected_float_large.example.cpp"
// Generated model constructor
#include "vts_models/fully_connected_float_large.model.cpp"
} // namespace fully_connected_float_large

TEST_F(NeuralnetworksHidlTest, fully_connected_float_large) {
  generated_tests::Execute(device,
                           fully_connected_float_large::createTestModel,
                           fully_connected_float_large::is_ignored,
                           fully_connected_float_large::examples);
}

// Generated from: fully_connected_float_large_weights_as_inputs.mod.py.
namespace fully_connected_float_large_weights_as_inputs {
// Generated fully_connected_float_large_weights_as_inputs test
#include "examples/fully_connected_float_large_weights_as_inputs.example.cpp"
// Generated model constructor
#include "vts_models/fully_connected_float_large_weights_as_inputs.model.cpp"
} // namespace fully_connected_float_large_weights_as_inputs

TEST_F(NeuralnetworksHidlTest, fully_connected_float_large_weights_as_inputs) {
  generated_tests::Execute(device,
                           fully_connected_float_large_weights_as_inputs::createTestModel,
                           fully_connected_float_large_weights_as_inputs::is_ignored,
                           fully_connected_float_large_weights_as_inputs::examples);
}

// Generated from: fully_connected_float_weights_as_inputs.mod.py.
namespace fully_connected_float_weights_as_inputs {
// Generated fully_connected_float_weights_as_inputs test
#include "examples/fully_connected_float_weights_as_inputs.example.cpp"
// Generated model constructor
#include "vts_models/fully_connected_float_weights_as_inputs.model.cpp"
} // namespace fully_connected_float_weights_as_inputs

TEST_F(NeuralnetworksHidlTest, fully_connected_float_weights_as_inputs) {
  generated_tests::Execute(device,
                           fully_connected_float_weights_as_inputs::createTestModel,
                           fully_connected_float_weights_as_inputs::is_ignored,
                           fully_connected_float_weights_as_inputs::examples);
}

// Generated from: fully_connected_quant8.mod.py.
namespace fully_connected_quant8 {
// Generated fully_connected_quant8 test
#include "examples/fully_connected_quant8.example.cpp"
// Generated model constructor
#include "vts_models/fully_connected_quant8.model.cpp"
} // namespace fully_connected_quant8

TEST_F(NeuralnetworksHidlTest, fully_connected_quant8) {
  generated_tests::Execute(device,
                           fully_connected_quant8::createTestModel,
                           fully_connected_quant8::is_ignored,
                           fully_connected_quant8::examples);
}

// Generated from: fully_connected_quant8_2.mod.py.
namespace fully_connected_quant8_2 {
// Generated fully_connected_quant8_2 test
#include "examples/fully_connected_quant8_2.example.cpp"
// Generated model constructor
#include "vts_models/fully_connected_quant8_2.model.cpp"
} // namespace fully_connected_quant8_2

TEST_F(NeuralnetworksHidlTest, fully_connected_quant8_2) {
  generated_tests::Execute(device,
                           fully_connected_quant8_2::createTestModel,
                           fully_connected_quant8_2::is_ignored,
                           fully_connected_quant8_2::examples);
}

// Generated from: fully_connected_quant8_large.mod.py.
namespace fully_connected_quant8_large {
// Generated fully_connected_quant8_large test
#include "examples/fully_connected_quant8_large.example.cpp"
// Generated model constructor
#include "vts_models/fully_connected_quant8_large.model.cpp"
} // namespace fully_connected_quant8_large

TEST_F(NeuralnetworksHidlTest, fully_connected_quant8_large) {
  generated_tests::Execute(device,
                           fully_connected_quant8_large::createTestModel,
                           fully_connected_quant8_large::is_ignored,
                           fully_connected_quant8_large::examples);
}

// Generated from: fully_connected_quant8_large_weights_as_inputs.mod.py.
namespace fully_connected_quant8_large_weights_as_inputs {
// Generated fully_connected_quant8_large_weights_as_inputs test
#include "examples/fully_connected_quant8_large_weights_as_inputs.example.cpp"
// Generated model constructor
#include "vts_models/fully_connected_quant8_large_weights_as_inputs.model.cpp"
} // namespace fully_connected_quant8_large_weights_as_inputs

TEST_F(NeuralnetworksHidlTest, fully_connected_quant8_large_weights_as_inputs) {
  generated_tests::Execute(device,
                           fully_connected_quant8_large_weights_as_inputs::createTestModel,
                           fully_connected_quant8_large_weights_as_inputs::is_ignored,
                           fully_connected_quant8_large_weights_as_inputs::examples);
}

// Generated from: fully_connected_quant8_weights_as_inputs.mod.py.
namespace fully_connected_quant8_weights_as_inputs {
// Generated fully_connected_quant8_weights_as_inputs test
#include "examples/fully_connected_quant8_weights_as_inputs.example.cpp"
// Generated model constructor
#include "vts_models/fully_connected_quant8_weights_as_inputs.model.cpp"
} // namespace fully_connected_quant8_weights_as_inputs

TEST_F(NeuralnetworksHidlTest, fully_connected_quant8_weights_as_inputs) {
  generated_tests::Execute(device,
                           fully_connected_quant8_weights_as_inputs::createTestModel,
                           fully_connected_quant8_weights_as_inputs::is_ignored,
                           fully_connected_quant8_weights_as_inputs::examples);
}

// Generated from: hashtable_lookup_float.mod.py.
namespace hashtable_lookup_float {
// Generated hashtable_lookup_float test
#include "examples/hashtable_lookup_float.example.cpp"
// Generated model constructor
#include "vts_models/hashtable_lookup_float.model.cpp"
} // namespace hashtable_lookup_float

TEST_F(NeuralnetworksHidlTest, hashtable_lookup_float) {
  generated_tests::Execute(device,
                           hashtable_lookup_float::createTestModel,
                           hashtable_lookup_float::is_ignored,
                           hashtable_lookup_float::examples);
}

// Generated from: hashtable_lookup_quant8.mod.py.
namespace hashtable_lookup_quant8 {
// Generated hashtable_lookup_quant8 test
#include "examples/hashtable_lookup_quant8.example.cpp"
// Generated model constructor
#include "vts_models/hashtable_lookup_quant8.model.cpp"
} // namespace hashtable_lookup_quant8

TEST_F(NeuralnetworksHidlTest, hashtable_lookup_quant8) {
  generated_tests::Execute(device,
                           hashtable_lookup_quant8::createTestModel,
                           hashtable_lookup_quant8::is_ignored,
                           hashtable_lookup_quant8::examples);
}

// Generated from: l2_normalization.mod.py.
namespace l2_normalization {
// Generated l2_normalization test
#include "examples/l2_normalization.example.cpp"
// Generated model constructor
#include "vts_models/l2_normalization.model.cpp"
} // namespace l2_normalization

TEST_F(NeuralnetworksHidlTest, l2_normalization) {
  generated_tests::Execute(device,
                           l2_normalization::createTestModel,
                           l2_normalization::is_ignored,
                           l2_normalization::examples);
}

// Generated from: l2_normalization_2.mod.py.
namespace l2_normalization_2 {
// Generated l2_normalization_2 test
#include "examples/l2_normalization_2.example.cpp"
// Generated model constructor
#include "vts_models/l2_normalization_2.model.cpp"
} // namespace l2_normalization_2

TEST_F(NeuralnetworksHidlTest, l2_normalization_2) {
  generated_tests::Execute(device,
                           l2_normalization_2::createTestModel,
                           l2_normalization_2::is_ignored,
                           l2_normalization_2::examples);
}

// Generated from: l2_normalization_large.mod.py.
namespace l2_normalization_large {
// Generated l2_normalization_large test
#include "examples/l2_normalization_large.example.cpp"
// Generated model constructor
#include "vts_models/l2_normalization_large.model.cpp"
} // namespace l2_normalization_large

TEST_F(NeuralnetworksHidlTest, l2_normalization_large) {
  generated_tests::Execute(device,
                           l2_normalization_large::createTestModel,
                           l2_normalization_large::is_ignored,
                           l2_normalization_large::examples);
}

// Generated from: l2_pool_float.mod.py.
namespace l2_pool_float {
// Generated l2_pool_float test
#include "examples/l2_pool_float.example.cpp"
// Generated model constructor
#include "vts_models/l2_pool_float.model.cpp"
} // namespace l2_pool_float

TEST_F(NeuralnetworksHidlTest, l2_pool_float) {
  generated_tests::Execute(device,
                           l2_pool_float::createTestModel,
                           l2_pool_float::is_ignored,
                           l2_pool_float::examples);
}

// Generated from: l2_pool_float_2.mod.py.
namespace l2_pool_float_2 {
// Generated l2_pool_float_2 test
#include "examples/l2_pool_float_2.example.cpp"
// Generated model constructor
#include "vts_models/l2_pool_float_2.model.cpp"
} // namespace l2_pool_float_2

TEST_F(NeuralnetworksHidlTest, l2_pool_float_2) {
  generated_tests::Execute(device,
                           l2_pool_float_2::createTestModel,
                           l2_pool_float_2::is_ignored,
                           l2_pool_float_2::examples);
}

// Generated from: l2_pool_float_large.mod.py.
namespace l2_pool_float_large {
// Generated l2_pool_float_large test
#include "examples/l2_pool_float_large.example.cpp"
// Generated model constructor
#include "vts_models/l2_pool_float_large.model.cpp"
} // namespace l2_pool_float_large

TEST_F(NeuralnetworksHidlTest, l2_pool_float_large) {
  generated_tests::Execute(device,
                           l2_pool_float_large::createTestModel,
                           l2_pool_float_large::is_ignored,
                           l2_pool_float_large::examples);
}

// Generated from: local_response_norm_float_1.mod.py.
namespace local_response_norm_float_1 {
// Generated local_response_norm_float_1 test
#include "examples/local_response_norm_float_1.example.cpp"
// Generated model constructor
#include "vts_models/local_response_norm_float_1.model.cpp"
} // namespace local_response_norm_float_1

TEST_F(NeuralnetworksHidlTest, local_response_norm_float_1) {
  generated_tests::Execute(device,
                           local_response_norm_float_1::createTestModel,
                           local_response_norm_float_1::is_ignored,
                           local_response_norm_float_1::examples);
}

// Generated from: local_response_norm_float_2.mod.py.
namespace local_response_norm_float_2 {
// Generated local_response_norm_float_2 test
#include "examples/local_response_norm_float_2.example.cpp"
// Generated model constructor
#include "vts_models/local_response_norm_float_2.model.cpp"
} // namespace local_response_norm_float_2

TEST_F(NeuralnetworksHidlTest, local_response_norm_float_2) {
  generated_tests::Execute(device,
                           local_response_norm_float_2::createTestModel,
                           local_response_norm_float_2::is_ignored,
                           local_response_norm_float_2::examples);
}

// Generated from: local_response_norm_float_3.mod.py.
namespace local_response_norm_float_3 {
// Generated local_response_norm_float_3 test
#include "examples/local_response_norm_float_3.example.cpp"
// Generated model constructor
#include "vts_models/local_response_norm_float_3.model.cpp"
} // namespace local_response_norm_float_3

TEST_F(NeuralnetworksHidlTest, local_response_norm_float_3) {
  generated_tests::Execute(device,
                           local_response_norm_float_3::createTestModel,
                           local_response_norm_float_3::is_ignored,
                           local_response_norm_float_3::examples);
}

// Generated from: local_response_norm_float_4.mod.py.
namespace local_response_norm_float_4 {
// Generated local_response_norm_float_4 test
#include "examples/local_response_norm_float_4.example.cpp"
// Generated model constructor
#include "vts_models/local_response_norm_float_4.model.cpp"
} // namespace local_response_norm_float_4

TEST_F(NeuralnetworksHidlTest, local_response_norm_float_4) {
  generated_tests::Execute(device,
                           local_response_norm_float_4::createTestModel,
                           local_response_norm_float_4::is_ignored,
                           local_response_norm_float_4::examples);
}

// Generated from: logistic_float_1.mod.py.
namespace logistic_float_1 {
// Generated logistic_float_1 test
#include "examples/logistic_float_1.example.cpp"
// Generated model constructor
#include "vts_models/logistic_float_1.model.cpp"
} // namespace logistic_float_1

TEST_F(NeuralnetworksHidlTest, logistic_float_1) {
  generated_tests::Execute(device,
                           logistic_float_1::createTestModel,
                           logistic_float_1::is_ignored,
                           logistic_float_1::examples);
}

// Generated from: logistic_float_2.mod.py.
namespace logistic_float_2 {
// Generated logistic_float_2 test
#include "examples/logistic_float_2.example.cpp"
// Generated model constructor
#include "vts_models/logistic_float_2.model.cpp"
} // namespace logistic_float_2

TEST_F(NeuralnetworksHidlTest, logistic_float_2) {
  generated_tests::Execute(device,
                           logistic_float_2::createTestModel,
                           logistic_float_2::is_ignored,
                           logistic_float_2::examples);
}

// Generated from: logistic_quant8_1.mod.py.
namespace logistic_quant8_1 {
// Generated logistic_quant8_1 test
#include "examples/logistic_quant8_1.example.cpp"
// Generated model constructor
#include "vts_models/logistic_quant8_1.model.cpp"
} // namespace logistic_quant8_1

TEST_F(NeuralnetworksHidlTest, logistic_quant8_1) {
  generated_tests::Execute(device,
                           logistic_quant8_1::createTestModel,
                           logistic_quant8_1::is_ignored,
                           logistic_quant8_1::examples);
}

// Generated from: logistic_quant8_2.mod.py.
namespace logistic_quant8_2 {
// Generated logistic_quant8_2 test
#include "examples/logistic_quant8_2.example.cpp"
// Generated model constructor
#include "vts_models/logistic_quant8_2.model.cpp"
} // namespace logistic_quant8_2

TEST_F(NeuralnetworksHidlTest, logistic_quant8_2) {
  generated_tests::Execute(device,
                           logistic_quant8_2::createTestModel,
                           logistic_quant8_2::is_ignored,
                           logistic_quant8_2::examples);
}

// Generated from: lsh_projection.mod.py.
namespace lsh_projection {
// Generated lsh_projection test
#include "examples/lsh_projection.example.cpp"
// Generated model constructor
#include "vts_models/lsh_projection.model.cpp"
} // namespace lsh_projection

TEST_F(NeuralnetworksHidlTest, lsh_projection) {
  generated_tests::Execute(device,
                           lsh_projection::createTestModel,
                           lsh_projection::is_ignored,
                           lsh_projection::examples);
}

// Generated from: lsh_projection_2.mod.py.
namespace lsh_projection_2 {
// Generated lsh_projection_2 test
#include "examples/lsh_projection_2.example.cpp"
// Generated model constructor
#include "vts_models/lsh_projection_2.model.cpp"
} // namespace lsh_projection_2

TEST_F(NeuralnetworksHidlTest, lsh_projection_2) {
  generated_tests::Execute(device,
                           lsh_projection_2::createTestModel,
                           lsh_projection_2::is_ignored,
                           lsh_projection_2::examples);
}

// Generated from: lsh_projection_weights_as_inputs.mod.py.
namespace lsh_projection_weights_as_inputs {
// Generated lsh_projection_weights_as_inputs test
#include "examples/lsh_projection_weights_as_inputs.example.cpp"
// Generated model constructor
#include "vts_models/lsh_projection_weights_as_inputs.model.cpp"
} // namespace lsh_projection_weights_as_inputs

TEST_F(NeuralnetworksHidlTest, lsh_projection_weights_as_inputs) {
  generated_tests::Execute(device,
                           lsh_projection_weights_as_inputs::createTestModel,
                           lsh_projection_weights_as_inputs::is_ignored,
                           lsh_projection_weights_as_inputs::examples);
}

// Generated from: lstm.mod.py.
namespace lstm {
// Generated lstm test
#include "examples/lstm.example.cpp"
// Generated model constructor
#include "vts_models/lstm.model.cpp"
} // namespace lstm

TEST_F(NeuralnetworksHidlTest, lstm) {
  generated_tests::Execute(device,
                           lstm::createTestModel,
                           lstm::is_ignored,
                           lstm::examples);
}

// Generated from: lstm2.mod.py.
namespace lstm2 {
// Generated lstm2 test
#include "examples/lstm2.example.cpp"
// Generated model constructor
#include "vts_models/lstm2.model.cpp"
} // namespace lstm2

TEST_F(NeuralnetworksHidlTest, lstm2) {
  generated_tests::Execute(device,
                           lstm2::createTestModel,
                           lstm2::is_ignored,
                           lstm2::examples);
}

// Generated from: lstm2_state.mod.py.
namespace lstm2_state {
// Generated lstm2_state test
#include "examples/lstm2_state.example.cpp"
// Generated model constructor
#include "vts_models/lstm2_state.model.cpp"
} // namespace lstm2_state

TEST_F(NeuralnetworksHidlTest, lstm2_state) {
  generated_tests::Execute(device,
                           lstm2_state::createTestModel,
                           lstm2_state::is_ignored,
                           lstm2_state::examples);
}

// Generated from: lstm2_state2.mod.py.
namespace lstm2_state2 {
// Generated lstm2_state2 test
#include "examples/lstm2_state2.example.cpp"
// Generated model constructor
#include "vts_models/lstm2_state2.model.cpp"
} // namespace lstm2_state2

TEST_F(NeuralnetworksHidlTest, lstm2_state2) {
  generated_tests::Execute(device,
                           lstm2_state2::createTestModel,
                           lstm2_state2::is_ignored,
                           lstm2_state2::examples);
}

// Generated from: lstm3.mod.py.
namespace lstm3 {
// Generated lstm3 test
#include "examples/lstm3.example.cpp"
// Generated model constructor
#include "vts_models/lstm3.model.cpp"
} // namespace lstm3

TEST_F(NeuralnetworksHidlTest, lstm3) {
  generated_tests::Execute(device,
                           lstm3::createTestModel,
                           lstm3::is_ignored,
                           lstm3::examples);
}

// Generated from: lstm3_state.mod.py.
namespace lstm3_state {
// Generated lstm3_state test
#include "examples/lstm3_state.example.cpp"
// Generated model constructor
#include "vts_models/lstm3_state.model.cpp"
} // namespace lstm3_state

TEST_F(NeuralnetworksHidlTest, lstm3_state) {
  generated_tests::Execute(device,
                           lstm3_state::createTestModel,
                           lstm3_state::is_ignored,
                           lstm3_state::examples);
}

// Generated from: lstm3_state2.mod.py.
namespace lstm3_state2 {
// Generated lstm3_state2 test
#include "examples/lstm3_state2.example.cpp"
// Generated model constructor
#include "vts_models/lstm3_state2.model.cpp"
} // namespace lstm3_state2

TEST_F(NeuralnetworksHidlTest, lstm3_state2) {
  generated_tests::Execute(device,
                           lstm3_state2::createTestModel,
                           lstm3_state2::is_ignored,
                           lstm3_state2::examples);
}

// Generated from: lstm3_state3.mod.py.
namespace lstm3_state3 {
// Generated lstm3_state3 test
#include "examples/lstm3_state3.example.cpp"
// Generated model constructor
#include "vts_models/lstm3_state3.model.cpp"
} // namespace lstm3_state3

TEST_F(NeuralnetworksHidlTest, lstm3_state3) {
  generated_tests::Execute(device,
                           lstm3_state3::createTestModel,
                           lstm3_state3::is_ignored,
                           lstm3_state3::examples);
}

// Generated from: lstm_state.mod.py.
namespace lstm_state {
// Generated lstm_state test
#include "examples/lstm_state.example.cpp"
// Generated model constructor
#include "vts_models/lstm_state.model.cpp"
} // namespace lstm_state

TEST_F(NeuralnetworksHidlTest, lstm_state) {
  generated_tests::Execute(device,
                           lstm_state::createTestModel,
                           lstm_state::is_ignored,
                           lstm_state::examples);
}

// Generated from: lstm_state2.mod.py.
namespace lstm_state2 {
// Generated lstm_state2 test
#include "examples/lstm_state2.example.cpp"
// Generated model constructor
#include "vts_models/lstm_state2.model.cpp"
} // namespace lstm_state2

TEST_F(NeuralnetworksHidlTest, lstm_state2) {
  generated_tests::Execute(device,
                           lstm_state2::createTestModel,
                           lstm_state2::is_ignored,
                           lstm_state2::examples);
}

// Generated from: max_pool_float_1.mod.py.
namespace max_pool_float_1 {
// Generated max_pool_float_1 test
#include "examples/max_pool_float_1.example.cpp"
// Generated model constructor
#include "vts_models/max_pool_float_1.model.cpp"
} // namespace max_pool_float_1

TEST_F(NeuralnetworksHidlTest, max_pool_float_1) {
  generated_tests::Execute(device,
                           max_pool_float_1::createTestModel,
                           max_pool_float_1::is_ignored,
                           max_pool_float_1::examples);
}

// Generated from: max_pool_float_2.mod.py.
namespace max_pool_float_2 {
// Generated max_pool_float_2 test
#include "examples/max_pool_float_2.example.cpp"
// Generated model constructor
#include "vts_models/max_pool_float_2.model.cpp"
} // namespace max_pool_float_2

TEST_F(NeuralnetworksHidlTest, max_pool_float_2) {
  generated_tests::Execute(device,
                           max_pool_float_2::createTestModel,
                           max_pool_float_2::is_ignored,
                           max_pool_float_2::examples);
}

// Generated from: max_pool_float_3.mod.py.
namespace max_pool_float_3 {
// Generated max_pool_float_3 test
#include "examples/max_pool_float_3.example.cpp"
// Generated model constructor
#include "vts_models/max_pool_float_3.model.cpp"
} // namespace max_pool_float_3

TEST_F(NeuralnetworksHidlTest, max_pool_float_3) {
  generated_tests::Execute(device,
                           max_pool_float_3::createTestModel,
                           max_pool_float_3::is_ignored,
                           max_pool_float_3::examples);
}

// Generated from: max_pool_float_4.mod.py.
namespace max_pool_float_4 {
// Generated max_pool_float_4 test
#include "examples/max_pool_float_4.example.cpp"
// Generated model constructor
#include "vts_models/max_pool_float_4.model.cpp"
} // namespace max_pool_float_4

TEST_F(NeuralnetworksHidlTest, max_pool_float_4) {
  generated_tests::Execute(device,
                           max_pool_float_4::createTestModel,
                           max_pool_float_4::is_ignored,
                           max_pool_float_4::examples);
}

// Generated from: max_pool_quant8_1.mod.py.
namespace max_pool_quant8_1 {
// Generated max_pool_quant8_1 test
#include "examples/max_pool_quant8_1.example.cpp"
// Generated model constructor
#include "vts_models/max_pool_quant8_1.model.cpp"
} // namespace max_pool_quant8_1

TEST_F(NeuralnetworksHidlTest, max_pool_quant8_1) {
  generated_tests::Execute(device,
                           max_pool_quant8_1::createTestModel,
                           max_pool_quant8_1::is_ignored,
                           max_pool_quant8_1::examples);
}

// Generated from: max_pool_quant8_2.mod.py.
namespace max_pool_quant8_2 {
// Generated max_pool_quant8_2 test
#include "examples/max_pool_quant8_2.example.cpp"
// Generated model constructor
#include "vts_models/max_pool_quant8_2.model.cpp"
} // namespace max_pool_quant8_2

TEST_F(NeuralnetworksHidlTest, max_pool_quant8_2) {
  generated_tests::Execute(device,
                           max_pool_quant8_2::createTestModel,
                           max_pool_quant8_2::is_ignored,
                           max_pool_quant8_2::examples);
}

// Generated from: max_pool_quant8_3.mod.py.
namespace max_pool_quant8_3 {
// Generated max_pool_quant8_3 test
#include "examples/max_pool_quant8_3.example.cpp"
// Generated model constructor
#include "vts_models/max_pool_quant8_3.model.cpp"
} // namespace max_pool_quant8_3

TEST_F(NeuralnetworksHidlTest, max_pool_quant8_3) {
  generated_tests::Execute(device,
                           max_pool_quant8_3::createTestModel,
                           max_pool_quant8_3::is_ignored,
                           max_pool_quant8_3::examples);
}

// Generated from: max_pool_quant8_4.mod.py.
namespace max_pool_quant8_4 {
// Generated max_pool_quant8_4 test
#include "examples/max_pool_quant8_4.example.cpp"
// Generated model constructor
#include "vts_models/max_pool_quant8_4.model.cpp"
} // namespace max_pool_quant8_4

TEST_F(NeuralnetworksHidlTest, max_pool_quant8_4) {
  generated_tests::Execute(device,
                           max_pool_quant8_4::createTestModel,
                           max_pool_quant8_4::is_ignored,
                           max_pool_quant8_4::examples);
}

// Generated from: mobilenet_224_gender_basic_fixed.mod.py.
namespace mobilenet_224_gender_basic_fixed {
// Generated mobilenet_224_gender_basic_fixed test
#include "examples/mobilenet_224_gender_basic_fixed.example.cpp"
// Generated model constructor
#include "vts_models/mobilenet_224_gender_basic_fixed.model.cpp"
} // namespace mobilenet_224_gender_basic_fixed

TEST_F(NeuralnetworksHidlTest, mobilenet_224_gender_basic_fixed) {
  generated_tests::Execute(device,
                           mobilenet_224_gender_basic_fixed::createTestModel,
                           mobilenet_224_gender_basic_fixed::is_ignored,
                           mobilenet_224_gender_basic_fixed::examples);
}

// Generated from: mobilenet_quantized.mod.py.
namespace mobilenet_quantized {
// Generated mobilenet_quantized test
#include "examples/mobilenet_quantized.example.cpp"
// Generated model constructor
#include "vts_models/mobilenet_quantized.model.cpp"
} // namespace mobilenet_quantized

TEST_F(NeuralnetworksHidlTest, mobilenet_quantized) {
  generated_tests::Execute(device,
                           mobilenet_quantized::createTestModel,
                           mobilenet_quantized::is_ignored,
                           mobilenet_quantized::examples);
}

// Generated from: mul.mod.py.
namespace mul {
// Generated mul test
#include "examples/mul.example.cpp"
// Generated model constructor
#include "vts_models/mul.model.cpp"
} // namespace mul

TEST_F(NeuralnetworksHidlTest, mul) {
  generated_tests::Execute(device,
                           mul::createTestModel,
                           mul::is_ignored,
                           mul::examples);
}

// Generated from: mul_broadcast_quant8.mod.py.
namespace mul_broadcast_quant8 {
// Generated mul_broadcast_quant8 test
#include "examples/mul_broadcast_quant8.example.cpp"
// Generated model constructor
#include "vts_models/mul_broadcast_quant8.model.cpp"
} // namespace mul_broadcast_quant8

TEST_F(NeuralnetworksHidlTest, mul_broadcast_quant8) {
  generated_tests::Execute(device,
                           mul_broadcast_quant8::createTestModel,
                           mul_broadcast_quant8::is_ignored,
                           mul_broadcast_quant8::examples);
}

// Generated from: mul_quant8.mod.py.
namespace mul_quant8 {
// Generated mul_quant8 test
#include "examples/mul_quant8.example.cpp"
// Generated model constructor
#include "vts_models/mul_quant8.model.cpp"
} // namespace mul_quant8

TEST_F(NeuralnetworksHidlTest, mul_quant8) {
  generated_tests::Execute(device,
                           mul_quant8::createTestModel,
                           mul_quant8::is_ignored,
                           mul_quant8::examples);
}

// Generated from: mul_relu.mod.py.
namespace mul_relu {
// Generated mul_relu test
#include "examples/mul_relu.example.cpp"
// Generated model constructor
#include "vts_models/mul_relu.model.cpp"
} // namespace mul_relu

TEST_F(NeuralnetworksHidlTest, mul_relu) {
  generated_tests::Execute(device,
                           mul_relu::createTestModel,
                           mul_relu::is_ignored,
                           mul_relu::examples);
}

// Generated from: relu1_float_1.mod.py.
namespace relu1_float_1 {
// Generated relu1_float_1 test
#include "examples/relu1_float_1.example.cpp"
// Generated model constructor
#include "vts_models/relu1_float_1.model.cpp"
} // namespace relu1_float_1

TEST_F(NeuralnetworksHidlTest, relu1_float_1) {
  generated_tests::Execute(device,
                           relu1_float_1::createTestModel,
                           relu1_float_1::is_ignored,
                           relu1_float_1::examples);
}

// Generated from: relu1_float_2.mod.py.
namespace relu1_float_2 {
// Generated relu1_float_2 test
#include "examples/relu1_float_2.example.cpp"
// Generated model constructor
#include "vts_models/relu1_float_2.model.cpp"
} // namespace relu1_float_2

TEST_F(NeuralnetworksHidlTest, relu1_float_2) {
  generated_tests::Execute(device,
                           relu1_float_2::createTestModel,
                           relu1_float_2::is_ignored,
                           relu1_float_2::examples);
}

// Generated from: relu1_quant8_1.mod.py.
namespace relu1_quant8_1 {
// Generated relu1_quant8_1 test
#include "examples/relu1_quant8_1.example.cpp"
// Generated model constructor
#include "vts_models/relu1_quant8_1.model.cpp"
} // namespace relu1_quant8_1

TEST_F(NeuralnetworksHidlTest, relu1_quant8_1) {
  generated_tests::Execute(device,
                           relu1_quant8_1::createTestModel,
                           relu1_quant8_1::is_ignored,
                           relu1_quant8_1::examples);
}

// Generated from: relu1_quant8_2.mod.py.
namespace relu1_quant8_2 {
// Generated relu1_quant8_2 test
#include "examples/relu1_quant8_2.example.cpp"
// Generated model constructor
#include "vts_models/relu1_quant8_2.model.cpp"
} // namespace relu1_quant8_2

TEST_F(NeuralnetworksHidlTest, relu1_quant8_2) {
  generated_tests::Execute(device,
                           relu1_quant8_2::createTestModel,
                           relu1_quant8_2::is_ignored,
                           relu1_quant8_2::examples);
}

// Generated from: relu6_float_1.mod.py.
namespace relu6_float_1 {
// Generated relu6_float_1 test
#include "examples/relu6_float_1.example.cpp"
// Generated model constructor
#include "vts_models/relu6_float_1.model.cpp"
} // namespace relu6_float_1

TEST_F(NeuralnetworksHidlTest, relu6_float_1) {
  generated_tests::Execute(device,
                           relu6_float_1::createTestModel,
                           relu6_float_1::is_ignored,
                           relu6_float_1::examples);
}

// Generated from: relu6_float_2.mod.py.
namespace relu6_float_2 {
// Generated relu6_float_2 test
#include "examples/relu6_float_2.example.cpp"
// Generated model constructor
#include "vts_models/relu6_float_2.model.cpp"
} // namespace relu6_float_2

TEST_F(NeuralnetworksHidlTest, relu6_float_2) {
  generated_tests::Execute(device,
                           relu6_float_2::createTestModel,
                           relu6_float_2::is_ignored,
                           relu6_float_2::examples);
}

// Generated from: relu6_quant8_1.mod.py.
namespace relu6_quant8_1 {
// Generated relu6_quant8_1 test
#include "examples/relu6_quant8_1.example.cpp"
// Generated model constructor
#include "vts_models/relu6_quant8_1.model.cpp"
} // namespace relu6_quant8_1

TEST_F(NeuralnetworksHidlTest, relu6_quant8_1) {
  generated_tests::Execute(device,
                           relu6_quant8_1::createTestModel,
                           relu6_quant8_1::is_ignored,
                           relu6_quant8_1::examples);
}

// Generated from: relu6_quant8_2.mod.py.
namespace relu6_quant8_2 {
// Generated relu6_quant8_2 test
#include "examples/relu6_quant8_2.example.cpp"
// Generated model constructor
#include "vts_models/relu6_quant8_2.model.cpp"
} // namespace relu6_quant8_2

TEST_F(NeuralnetworksHidlTest, relu6_quant8_2) {
  generated_tests::Execute(device,
                           relu6_quant8_2::createTestModel,
                           relu6_quant8_2::is_ignored,
                           relu6_quant8_2::examples);
}

// Generated from: relu_float_1.mod.py.
namespace relu_float_1 {
// Generated relu_float_1 test
#include "examples/relu_float_1.example.cpp"
// Generated model constructor
#include "vts_models/relu_float_1.model.cpp"
} // namespace relu_float_1

TEST_F(NeuralnetworksHidlTest, relu_float_1) {
  generated_tests::Execute(device,
                           relu_float_1::createTestModel,
                           relu_float_1::is_ignored,
                           relu_float_1::examples);
}

// Generated from: relu_float_2.mod.py.
namespace relu_float_2 {
// Generated relu_float_2 test
#include "examples/relu_float_2.example.cpp"
// Generated model constructor
#include "vts_models/relu_float_2.model.cpp"
} // namespace relu_float_2

TEST_F(NeuralnetworksHidlTest, relu_float_2) {
  generated_tests::Execute(device,
                           relu_float_2::createTestModel,
                           relu_float_2::is_ignored,
                           relu_float_2::examples);
}

// Generated from: relu_quant8_1.mod.py.
namespace relu_quant8_1 {
// Generated relu_quant8_1 test
#include "examples/relu_quant8_1.example.cpp"
// Generated model constructor
#include "vts_models/relu_quant8_1.model.cpp"
} // namespace relu_quant8_1

TEST_F(NeuralnetworksHidlTest, relu_quant8_1) {
  generated_tests::Execute(device,
                           relu_quant8_1::createTestModel,
                           relu_quant8_1::is_ignored,
                           relu_quant8_1::examples);
}

// Generated from: relu_quant8_2.mod.py.
namespace relu_quant8_2 {
// Generated relu_quant8_2 test
#include "examples/relu_quant8_2.example.cpp"
// Generated model constructor
#include "vts_models/relu_quant8_2.model.cpp"
} // namespace relu_quant8_2

TEST_F(NeuralnetworksHidlTest, relu_quant8_2) {
  generated_tests::Execute(device,
                           relu_quant8_2::createTestModel,
                           relu_quant8_2::is_ignored,
                           relu_quant8_2::examples);
}

// Generated from: reshape.mod.py.
namespace reshape {
// Generated reshape test
#include "examples/reshape.example.cpp"
// Generated model constructor
#include "vts_models/reshape.model.cpp"
} // namespace reshape

TEST_F(NeuralnetworksHidlTest, reshape) {
  generated_tests::Execute(device,
                           reshape::createTestModel,
                           reshape::is_ignored,
                           reshape::examples);
}

// Generated from: reshape_quant8.mod.py.
namespace reshape_quant8 {
// Generated reshape_quant8 test
#include "examples/reshape_quant8.example.cpp"
// Generated model constructor
#include "vts_models/reshape_quant8.model.cpp"
} // namespace reshape_quant8

TEST_F(NeuralnetworksHidlTest, reshape_quant8) {
  generated_tests::Execute(device,
                           reshape_quant8::createTestModel,
                           reshape_quant8::is_ignored,
                           reshape_quant8::examples);
}

// Generated from: reshape_quant8_weights_as_inputs.mod.py.
namespace reshape_quant8_weights_as_inputs {
// Generated reshape_quant8_weights_as_inputs test
#include "examples/reshape_quant8_weights_as_inputs.example.cpp"
// Generated model constructor
#include "vts_models/reshape_quant8_weights_as_inputs.model.cpp"
} // namespace reshape_quant8_weights_as_inputs

TEST_F(NeuralnetworksHidlTest, reshape_quant8_weights_as_inputs) {
  generated_tests::Execute(device,
                           reshape_quant8_weights_as_inputs::createTestModel,
                           reshape_quant8_weights_as_inputs::is_ignored,
                           reshape_quant8_weights_as_inputs::examples);
}

// Generated from: reshape_weights_as_inputs.mod.py.
namespace reshape_weights_as_inputs {
// Generated reshape_weights_as_inputs test
#include "examples/reshape_weights_as_inputs.example.cpp"
// Generated model constructor
#include "vts_models/reshape_weights_as_inputs.model.cpp"
} // namespace reshape_weights_as_inputs

TEST_F(NeuralnetworksHidlTest, reshape_weights_as_inputs) {
  generated_tests::Execute(device,
                           reshape_weights_as_inputs::createTestModel,
                           reshape_weights_as_inputs::is_ignored,
                           reshape_weights_as_inputs::examples);
}

// Generated from: resize_bilinear.mod.py.
namespace resize_bilinear {
// Generated resize_bilinear test
#include "examples/resize_bilinear.example.cpp"
// Generated model constructor
#include "vts_models/resize_bilinear.model.cpp"
} // namespace resize_bilinear

TEST_F(NeuralnetworksHidlTest, resize_bilinear) {
  generated_tests::Execute(device,
                           resize_bilinear::createTestModel,
                           resize_bilinear::is_ignored,
                           resize_bilinear::examples);
}

// Generated from: resize_bilinear_2.mod.py.
namespace resize_bilinear_2 {
// Generated resize_bilinear_2 test
#include "examples/resize_bilinear_2.example.cpp"
// Generated model constructor
#include "vts_models/resize_bilinear_2.model.cpp"
} // namespace resize_bilinear_2

TEST_F(NeuralnetworksHidlTest, resize_bilinear_2) {
  generated_tests::Execute(device,
                           resize_bilinear_2::createTestModel,
                           resize_bilinear_2::is_ignored,
                           resize_bilinear_2::examples);
}

// Generated from: rnn.mod.py.
namespace rnn {
// Generated rnn test
#include "examples/rnn.example.cpp"
// Generated model constructor
#include "vts_models/rnn.model.cpp"
} // namespace rnn

TEST_F(NeuralnetworksHidlTest, rnn) {
  generated_tests::Execute(device,
                           rnn::createTestModel,
                           rnn::is_ignored,
                           rnn::examples);
}

// Generated from: rnn_state.mod.py.
namespace rnn_state {
// Generated rnn_state test
#include "examples/rnn_state.example.cpp"
// Generated model constructor
#include "vts_models/rnn_state.model.cpp"
} // namespace rnn_state

TEST_F(NeuralnetworksHidlTest, rnn_state) {
  generated_tests::Execute(device,
                           rnn_state::createTestModel,
                           rnn_state::is_ignored,
                           rnn_state::examples);
}

// Generated from: softmax_float_1.mod.py.
namespace softmax_float_1 {
// Generated softmax_float_1 test
#include "examples/softmax_float_1.example.cpp"
// Generated model constructor
#include "vts_models/softmax_float_1.model.cpp"
} // namespace softmax_float_1

TEST_F(NeuralnetworksHidlTest, softmax_float_1) {
  generated_tests::Execute(device,
                           softmax_float_1::createTestModel,
                           softmax_float_1::is_ignored,
                           softmax_float_1::examples);
}

// Generated from: softmax_float_2.mod.py.
namespace softmax_float_2 {
// Generated softmax_float_2 test
#include "examples/softmax_float_2.example.cpp"
// Generated model constructor
#include "vts_models/softmax_float_2.model.cpp"
} // namespace softmax_float_2

TEST_F(NeuralnetworksHidlTest, softmax_float_2) {
  generated_tests::Execute(device,
                           softmax_float_2::createTestModel,
                           softmax_float_2::is_ignored,
                           softmax_float_2::examples);
}

// Generated from: softmax_quant8_1.mod.py.
namespace softmax_quant8_1 {
// Generated softmax_quant8_1 test
#include "examples/softmax_quant8_1.example.cpp"
// Generated model constructor
#include "vts_models/softmax_quant8_1.model.cpp"
} // namespace softmax_quant8_1

TEST_F(NeuralnetworksHidlTest, softmax_quant8_1) {
  generated_tests::Execute(device,
                           softmax_quant8_1::createTestModel,
                           softmax_quant8_1::is_ignored,
                           softmax_quant8_1::examples);
}

// Generated from: softmax_quant8_2.mod.py.
namespace softmax_quant8_2 {
// Generated softmax_quant8_2 test
#include "examples/softmax_quant8_2.example.cpp"
// Generated model constructor
#include "vts_models/softmax_quant8_2.model.cpp"
} // namespace softmax_quant8_2

TEST_F(NeuralnetworksHidlTest, softmax_quant8_2) {
  generated_tests::Execute(device,
                           softmax_quant8_2::createTestModel,
                           softmax_quant8_2::is_ignored,
                           softmax_quant8_2::examples);
}

// Generated from: space_to_depth_float_1.mod.py.
namespace space_to_depth_float_1 {
// Generated space_to_depth_float_1 test
#include "examples/space_to_depth_float_1.example.cpp"
// Generated model constructor
#include "vts_models/space_to_depth_float_1.model.cpp"
} // namespace space_to_depth_float_1

TEST_F(NeuralnetworksHidlTest, space_to_depth_float_1) {
  generated_tests::Execute(device,
                           space_to_depth_float_1::createTestModel,
                           space_to_depth_float_1::is_ignored,
                           space_to_depth_float_1::examples);
}

// Generated from: space_to_depth_float_2.mod.py.
namespace space_to_depth_float_2 {
// Generated space_to_depth_float_2 test
#include "examples/space_to_depth_float_2.example.cpp"
// Generated model constructor
#include "vts_models/space_to_depth_float_2.model.cpp"
} // namespace space_to_depth_float_2

TEST_F(NeuralnetworksHidlTest, space_to_depth_float_2) {
  generated_tests::Execute(device,
                           space_to_depth_float_2::createTestModel,
                           space_to_depth_float_2::is_ignored,
                           space_to_depth_float_2::examples);
}

// Generated from: space_to_depth_float_3.mod.py.
namespace space_to_depth_float_3 {
// Generated space_to_depth_float_3 test
#include "examples/space_to_depth_float_3.example.cpp"
// Generated model constructor
#include "vts_models/space_to_depth_float_3.model.cpp"
} // namespace space_to_depth_float_3

TEST_F(NeuralnetworksHidlTest, space_to_depth_float_3) {
  generated_tests::Execute(device,
                           space_to_depth_float_3::createTestModel,
                           space_to_depth_float_3::is_ignored,
                           space_to_depth_float_3::examples);
}

// Generated from: space_to_depth_quant8_1.mod.py.
namespace space_to_depth_quant8_1 {
// Generated space_to_depth_quant8_1 test
#include "examples/space_to_depth_quant8_1.example.cpp"
// Generated model constructor
#include "vts_models/space_to_depth_quant8_1.model.cpp"
} // namespace space_to_depth_quant8_1

TEST_F(NeuralnetworksHidlTest, space_to_depth_quant8_1) {
  generated_tests::Execute(device,
                           space_to_depth_quant8_1::createTestModel,
                           space_to_depth_quant8_1::is_ignored,
                           space_to_depth_quant8_1::examples);
}

// Generated from: space_to_depth_quant8_2.mod.py.
namespace space_to_depth_quant8_2 {
// Generated space_to_depth_quant8_2 test
#include "examples/space_to_depth_quant8_2.example.cpp"
// Generated model constructor
#include "vts_models/space_to_depth_quant8_2.model.cpp"
} // namespace space_to_depth_quant8_2

TEST_F(NeuralnetworksHidlTest, space_to_depth_quant8_2) {
  generated_tests::Execute(device,
                           space_to_depth_quant8_2::createTestModel,
                           space_to_depth_quant8_2::is_ignored,
                           space_to_depth_quant8_2::examples);
}

// Generated from: svdf.mod.py.
namespace svdf {
// Generated svdf test
#include "examples/svdf.example.cpp"
// Generated model constructor
#include "vts_models/svdf.model.cpp"
} // namespace svdf

TEST_F(NeuralnetworksHidlTest, svdf) {
  generated_tests::Execute(device,
                           svdf::createTestModel,
                           svdf::is_ignored,
                           svdf::examples);
}

// Generated from: svdf2.mod.py.
namespace svdf2 {
// Generated svdf2 test
#include "examples/svdf2.example.cpp"
// Generated model constructor
#include "vts_models/svdf2.model.cpp"
} // namespace svdf2

TEST_F(NeuralnetworksHidlTest, svdf2) {
  generated_tests::Execute(device,
                           svdf2::createTestModel,
                           svdf2::is_ignored,
                           svdf2::examples);
}

// Generated from: svdf_state.mod.py.
namespace svdf_state {
// Generated svdf_state test
#include "examples/svdf_state.example.cpp"
// Generated model constructor
#include "vts_models/svdf_state.model.cpp"
} // namespace svdf_state

TEST_F(NeuralnetworksHidlTest, svdf_state) {
  generated_tests::Execute(device,
                           svdf_state::createTestModel,
                           svdf_state::is_ignored,
                           svdf_state::examples);
}

// Generated from: tanh.mod.py.
namespace tanh {
// Generated tanh test
#include "examples/tanh.example.cpp"
// Generated model constructor
#include "vts_models/tanh.model.cpp"
} // namespace tanh

TEST_F(NeuralnetworksHidlTest, tanh) {
  generated_tests::Execute(device,
                           tanh::createTestModel,
                           tanh::is_ignored,
                           tanh::examples);
}

